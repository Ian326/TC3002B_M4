{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 4.4. Comparación entre técnicas de semejanza\n",
    "---\n",
    "Instituto Tecnológico y de Estudios Superiores de Monterrey\n",
    "\n",
    "Campus Querétaro\n",
    "\n",
    "TC3002B Desarrollo de aplicaciones avanzadas de ciencias computacionales\n",
    "\n",
    "Módulo 4 Resultados de la comparación entre técnicas de semejanza.\n",
    "\n",
    "Profesores:\n",
    "\n",
    "Manuel Iván Casillas del Llano\n",
    "\n",
    "\n",
    "Presenta:\n",
    "\n",
    "**Ian Joab Padron Corona - A01708940**\n",
    "\n",
    "Fecha:\n",
    "\n",
    "Miércoles, 23 de abril del 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Ian326/TC3002B_M4/blob/main/A01708940_Actividad%204.4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "\n",
    "from numpy.typing import ArrayLike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_series(file: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Reads a TXT file and returns a pandas Series where each line is an entry.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : `str` Name of the TXT file to read.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    series : `pd.Series` Containing the lines of the TXT file as entries.\n",
    "    \"\"\"\n",
    "    file_path = f'./content/{file}'\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    series = pd.Series([content.strip()])\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_file(file: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a CSV file and returns a pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : `str` Name of the CSV file to read.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : `DataFrame` Containing the data from the CSV file.\n",
    "    \"\"\"\n",
    "    file = f'./content/{file}'\n",
    "    data = pd.read_csv(file, header=0, encoding='utf-8')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans a text by removing special characters and converting it to lowercase.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : `str` Text to clean.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Cleaned text.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_words(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Splits a text into a list of words.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : `str` Text to split into words.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List of words.\n",
    "    \"\"\"\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueWords(q1: str, q2: str) -> list:\n",
    "    \"\"\"\n",
    "    Filters unique words from two text strings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    q1 : `str` First text string.\n",
    "    q2 : `str` Second text string.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List of unique words.\n",
    "    \"\"\"\n",
    "    words_q1 = array_words(q1)\n",
    "    words_q2 = array_words(q2)\n",
    "    unique_words = set(words_q1 + words_q2)\n",
    "    return list(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countWords(q: str, wordsq1q2: list, call:str) -> list:\n",
    "    \"\"\"\n",
    "    Counts the frequency of words in a text string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    q : `str` Text string.\n",
    "    wordsq1q2 : `list` List of words to count.\n",
    "    call : `str` Use case for the function. \n",
    "        `BoW` for Act4.2.\n",
    "\n",
    "        `TF` for Act4.3.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List of word frequencies in the text string.\n",
    "    \"\"\"\n",
    "    q_words = array_words(q)\n",
    "    wordsCount = []\n",
    "    for word in wordsq1q2:\n",
    "        if call == 'BoW':\n",
    "            wordsCount.append(q_words.count(word))\n",
    "        elif call == 'TF':\n",
    "            wordsCount.append(q_words.count(word) / len(q_words) if len(q_words) > 0 else 0)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid call type. Use 'BoW' or 'TF'.\")\n",
    "    return wordsCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(words: list, q1: str, q2: str) -> list:\n",
    "    \"\"\"\n",
    "    Calculates the IDF of a list of words in two text strings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    words : `list` List of words.\n",
    "    q1 : `str` First text string.\n",
    "    q2 : `str` Second text string.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List of IDF values for each word.\n",
    "    \"\"\"\n",
    "    idfs = []\n",
    "    for word in words:\n",
    "        docs_count = 0\n",
    "        if word in array_words(q1):\n",
    "            docs_count += 1\n",
    "        if word in array_words(q2):\n",
    "            docs_count += 1\n",
    "        idf = ((math.log(2 / (docs_count + 1))) + 1)\n",
    "        idfs.append(idf)\n",
    "    return idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfByIDF(tfQ: list, idf: list) -> list:\n",
    "    \"\"\"\n",
    "    Calculates the TF-IDF of a list of word frequencies and their IDF values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tfQ : `list` List of word frequencies.\n",
    "    idf : `list` List of IDF values for each word.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List of TF-IDF values for each word.\n",
    "    \"\"\"\n",
    "    return [tf * idf_val for tf, idf_val in zip(tfQ, idf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(tf_idf_q1: ArrayLike, tf_idf_q2: ArrayLike) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the cosine similarity between two TF-IDF vectors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tf_idf_q1 : `list` TF-IDF vector for the first text.\n",
    "    tf_idf_q2 : `list` TF-IDF vector for the second text.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Cosine similarity value.\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(tf_idf_q1, tf_idf_q2)\n",
    "    norm_q1 = np.linalg.norm(tf_idf_q1)\n",
    "    norm_q2 = np.linalg.norm(tf_idf_q2)\n",
    "    if norm_q1 == 0 or norm_q2 == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (dot_product / (norm_q1 * norm_q2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_follow(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Lists the words that follow each word in a text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : `str` Text to analyze.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary with words and their following words.\n",
    "    \"\"\"\n",
    "    arr_text = array_words(text)\n",
    "    follows = {}\n",
    "    for i in range(1, len(arr_text)):\n",
    "        if arr_text[i - 1] not in follows:\n",
    "            follows[arr_text[i - 1]] = [arr_text[i]]\n",
    "        else:\n",
    "            follows[arr_text[i - 1]].append(arr_text[i])\n",
    "    return follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_follow_matrix(bow: list, follows: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a matrix of words that follow other words.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bow : `list` List of words (Bag of Words).\n",
    "    follows : `dict` Dictionary with words and their following words.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Matrix of words that follow other words.\n",
    "    \"\"\"\n",
    "    matrix = []\n",
    "    for word in bow:\n",
    "        row = [0] * len(bow)\n",
    "        if word in follows:\n",
    "            for word_follow in follows[word]:\n",
    "                row[bow.index(word_follow)] += 1\n",
    "            row = [i / len(follows[word]) for i in row]\n",
    "        matrix.append(row)\n",
    "    return pd.DataFrame(matrix, index=bow, columns=bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_matrix(prod_int: float, m1: ArrayLike, m2: ArrayLike) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the cosine similarity between two matrices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    prod_int : `float` Inner product of the matrices.\n",
    "    m1 : `ArrayLike` First matrix.\n",
    "    m2 : `ArrayLike` Second matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Cosine similarity value between the matrices.\n",
    "    \"\"\"\n",
    "    norm_m1 = np.linalg.norm(m1)\n",
    "    norm_m2 = np.linalg.norm(m2)\n",
    "    if norm_m1 == 0 or norm_m2 == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (prod_int / (norm_m1 * norm_m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txts_to_df(original:str, similar_files:list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a DataFrame with the original text and similar texts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    original : `str` Original text.\n",
    "    similar : `list` List of similar texts.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame with the original text and similar texts.\n",
    "    \"\"\"\n",
    "    original_series = txt_to_series(original)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for file in similar_files:\n",
    "        file_series = txt_to_series(file)\n",
    "        sim_grade = file.split('_')[0]  # Extracts 'high', 'low', or 'moderate'\n",
    "        # Create a temporary DataFrame with 'original' and 'edited' columns\n",
    "        temp_df = pd.DataFrame({\n",
    "            'original': original_series,\n",
    "            'edited': file_series,\n",
    "            'simGrade': sim_grade\n",
    "        })\n",
    "\n",
    "        # Append the temporary DataFrame to the rows list\n",
    "        rows.append(temp_df)\n",
    "\n",
    "    return pd.concat(rows, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prediction(expected: str, predicted: float) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if the predicted value is within the expected range.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    expected : `str` Expected range in the format 'low', 'moderate', or 'high'.\n",
    "    predicted : `float` Predicted value.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool : True if the prediction is correct, False otherwise.\n",
    "    \"\"\"\n",
    "    if expected == 'low' and predicted >= 0 and predicted < 0.45:\n",
    "        return True\n",
    "    elif expected == 'moderate' and predicted >= 45 and predicted < 0.85:\n",
    "        return True\n",
    "    elif expected == 'high' and predicted >= 0.85:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura y Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el nombre del archivo\n",
    "original = 'original.txt'\n",
    "\n",
    "high_similarity = ['high_00.txt', 'high_01.txt', 'high_02.txt', 'high_03.txt']\n",
    "low_similarity = ['low_01.txt', 'low_02.txt', 'low_03.txt']\n",
    "moderate_similarity = ['moderate_01.txt', 'moderate_02.txt', 'moderate_03.txt']\n",
    "\n",
    "similar_files = high_similarity + low_similarity + moderate_similarity\n",
    "\n",
    "data = txts_to_df(original, similar_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una columna que contenga un array con todas las palabras de original y edited, sin duplicados\n",
    "data['BoWQ1Q2'] = data.apply(lambda x: uniqueWords(x['original'], x['edited']), axis=1)\n",
    "\n",
    "# Crear una columna que contenga un array con la cantidad de veces que aparece cada palabra de words en q1,q2\n",
    "data['q1_vecBoW'] = data.apply(lambda x: countWords(x['original'], x['BoWQ1Q2'], 'BoW'), axis=1)\n",
    "data['q2_vecBoW'] = data.apply(lambda x: countWords(x['edited'], x['BoWQ1Q2'], 'BoW'), axis=1)\n",
    "\n",
    "# Crear una columna que contenga el calculo del coseno entre los vecBow de q1 y q2\n",
    "data['cos_BOW'] = data.apply(lambda x: cosine_similarity(x['q1_vecBoW'], x['q2_vecBoW']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency / Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una columna que contenga un array con la cantidad de veces que aparece cada palabra de words en q1,q2\n",
    "data['TF_q1'] = data.apply(lambda x: countWords(x['original'], x['BoWQ1Q2'], 'TF'), axis=1)\n",
    "data['TF_q2'] = data.apply(lambda x: countWords(x['edited'], x['BoWQ1Q2'], 'TF'), axis=1)\n",
    "\n",
    "# Crear una columna que contenga el array de IDF's de cada palabra en words\n",
    "data['vecIDF'] = data.apply(lambda x: idf(x['BoWQ1Q2'], x['original'], x['edited']), axis=1)\n",
    "\n",
    "# Crear una columna que contenga el array de TF-IDF's de cada palabra en words\n",
    "data['q1_vecTFIDF'] = data.apply(lambda x: tfByIDF(x['TF_q1'], x['vecIDF']), axis=1)\n",
    "data['q2_vecTFIDF'] = data.apply(lambda x: tfByIDF(x['TF_q2'], x['vecIDF']), axis=1)\n",
    "\n",
    "# Crear una columna que contenga el calculo del coseno entre los TF-IDF de q1 y q2\n",
    "data['cos_TFID'] = data.apply(lambda x: cosine_similarity(x['q1_vecTFIDF'], x['q2_vecTFIDF']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cadenas de Markov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una columna con una diccionario de palabras que siguen a cada palabra en q1\n",
    "data['q1_wordsFollow'] = data.apply(lambda x: word_follow(x['original']), axis=1)\n",
    "data['q2_wordsFollow'] = data.apply(lambda x: word_follow(x['edited']), axis=1)\n",
    "\n",
    "# Crear una columna con una matriz de palabras que siguen a cada palabra en q1,q2\n",
    "data['q1_vecMark'] = data.apply(lambda x: word_follow_matrix(x['BoWQ1Q2'], x['q1_wordsFollow']), axis=1)\n",
    "data['q2_vecMark'] = data.apply(lambda x: word_follow_matrix(x['BoWQ1Q2'], x['q2_wordsFollow']), axis=1)\n",
    "\n",
    "# Transponer la matriz de q2\n",
    "data['q2T_vecMark'] = data.apply(lambda x: x['q2_vecMark'].T, axis=1)\n",
    "\n",
    "# Multiplicar las matrices de q1 y q2\n",
    "data['dotMatrix'] = data.apply(lambda x: x['q1_vecMark'].dot(x['q2T_vecMark']), axis=1)\n",
    "\n",
    "# Aplicar traza a la matriz de q1 y q2\n",
    "data['prod_int'] = data.apply(lambda x: np.trace(x['dotMatrix']), axis=1)\n",
    "\n",
    "# Crear una columna con el calculo del coseno entre las matrices de q1, q2 y su traza\n",
    "data['cos_MARK'] = data.apply(lambda x: cosine_similarity_matrix(x['prod_int'], \n",
    "                                                                               x['q1_vecMark'], \n",
    "                                                                               x['q2_vecMark']), \n",
    "                                                                               axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar flatten a las matrices de q1, q2, q2T y dotMatrix como indica la actividad\n",
    "data['q1_vecMark'] = data['q1_vecMark'].apply(lambda x: x.to_numpy().flatten())\n",
    "data['q2_vecMark'] = data['q2_vecMark'].apply(lambda x: x.to_numpy().flatten())\n",
    "data['q2T_vecMark'] = data['q2T_vecMark'].apply(lambda x: x.to_numpy().flatten())\n",
    "data['dotMatrix'] = data['dotMatrix'].apply(lambda x: x.to_numpy().flatten())\n",
    "\n",
    "# Remover columnas innecesarias\n",
    "data = data.drop(columns=['BoWQ1Q2', 'q1_vecBoW', 'q2_vecBoW', \n",
    "                          'TF_q1', 'TF_q2', 'vecIDF', 'q1_vecTFIDF', 'q2_vecTFIDF',\n",
    "                          'q1_wordsFollow', 'q2_wordsFollow', 'q1_vecMark', 'q2_vecMark', 'q2T_vecMark', 'dotMatrix',\n",
    "                          'prod_int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una columna 'BOW_correct' que muestre si la prediccion de cos_BOW es correcta\n",
    "data['BOW_correct'] = data.apply(lambda x: check_prediction(x['simGrade'], x['cos_BOW']), axis=1)\n",
    "# Crear una columna 'TFIDF_correct' que muestre si la prediccion de cos_TFID es correcta\n",
    "data['TFIDF_correct'] = data.apply(lambda x: check_prediction(x['simGrade'], x['cos_TFID']), axis=1)\n",
    "# Crear una columna 'MARK_correct' que muestre si la prediccion de cos_MARK es correcta\n",
    "data['MARK_correct'] = data.apply(lambda x: check_prediction(x['simGrade'], x['cos_MARK']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir cuantos aciertos y errores hubo en cada metodo\n",
    "data['BOW_correct'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TFIDF_correct'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['MARK_correct'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame en un archivo CSV\n",
    "data.to_csv('./outputs/compare_BoW_TF-IDF_Markov.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizando los resultados de esta implementación,es posible concluir que ninguna tecnica es realmente efectiva si los textos son lo suficientemente distintos entre las palabras que utilizan, aunque al final vengan diciendo lo mismo. Si bien cada uno de los metodos ofrecen un enfoque distinto a los demas, es importante aclarar que no son completamente satisfactorios, pues, aunque ofrecen soluciones similares, aún tienen desempeños bastante pobres en cuando a la deteccion del grado de similitud de semejanza en los textos."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
